{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6IotBqsqi8gfm5j8bTU2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/AdversarialModel/blob/master/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##quantification\n",
        "L'objectif de ce notebook est d'apprendre un réseau qui pourra être utilisé en int8.\n",
        "\n",
        "### speed up\n",
        "Regardons d'abord quelle est l'accélération qu'on peut espérer."
      ],
      "metadata": {
        "id": "hfkvfsm8D6yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lPxYWtRTXYYC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    T = torch.zeros(100,5)\n",
        "    for i in range(100):\n",
        "        A = torch.randint(-64, 64, (2000,1, 128), dtype=torch.int8).cuda()\n",
        "        B = torch.randint(-64, 64, (1,1000, 128), dtype=torch.int8).cuda()\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = torch.matmul(A[:,0,:].float(),B[0].float().t()).to(dtype=torch.int8)\n",
        "        tf = time.time()\n",
        "        T[i][0] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = torch._int_mm(A[:,0,:].to(dtype=torch.int8),B[0].t().to(dtype=torch.int8)).to(dtype=torch.int8)\n",
        "        tf = time.time()\n",
        "        T[i][1] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A.float()*B.float()).sum(-1).to(dtype=torch.int8)\n",
        "        tf = time.time()\n",
        "        T[i][2] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A.half()*B.half()).sum(-1,dtype=torch.half).to(dtype=torch.int8)\n",
        "        tf = time.time()\n",
        "        T[i][3] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A*B).sum(-1,dtype=torch.int8)\n",
        "        tf = time.time()\n",
        "        T[i][4] = tf-t0\n",
        "\n",
        "\n",
        "print(T.mean(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phRiggfFsu1",
        "outputId": "083b29e3-ae99-4885-b69d-fe6b0884f770"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.7651e-04, 7.7317e-05, 2.4205e-04, 7.0946e-05, 3.1669e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "on observe que le gain à espérer n'est pas du tout impressionnant - pire, la variance est très forte (ça semble dépendre du contenu de la matrice).\n",
        "néanmoins, cela testons quand même.\n",
        "\n",
        "### architecture\n",
        "\n",
        "Le point central du réseau sera que\n",
        "- si x est de dimension 8 avec ||x||_oo <= 5\n",
        "- si ||w||_oo<=3\n",
        "- alors |wx| <= 3 x 5 x 8 = 120\n",
        "- donc activation(x)//16 est toujours un vecteur de dimension 8 avec ||x||_oo <= 5"
      ],
      "metadata": {
        "id": "TFrYkajBGYS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "on peut donc construire le module \"MyLinear\""
      ],
      "metadata": {
        "id": "V7ru9xxeJwTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(x):\n",
        "    if x.dtype==torch.int8:\n",
        "        return torch.clamp(x,-17,81)//16\n",
        "    else:\n",
        "        return torch.clamp(x,-17,81)/16\n",
        "\n",
        "class MyLinear(torch.nn.Module):\n",
        "    def __init__(self,size):\n",
        "        super(MyLinear, self).__init__()\n",
        "        assert size%8==0\n",
        "        self.size=size\n",
        "        self.data = torch.rand(1,size//8,8,8).cuda() * 6 - 3\n",
        "        self.bias = torch.rand(1,size).cuda() * 6 - 3\n",
        "        self.data = torch.nn.Parameter(self.data)\n",
        "        self.bias = torch.nn.Parameter(self.bias)\n",
        "        self.floatmode = True\n",
        "\n",
        "    def clamp(self):\n",
        "        with torch.no_grad():\n",
        "            torch.clamp(self.data,-3,3)\n",
        "            torch.clamp(self.bias,-3,3)\n",
        "\n",
        "    def goINT(self):\n",
        "        if self.floatmode:\n",
        "            self.clamp()\n",
        "            with torch.no_grad():\n",
        "                tmp = torch.round(self.data.clone()).to(dtype=torch.int8)\n",
        "                tmpbis = torch.round(self.bias.clone()).to(dtype=torch.int8)\n",
        "                del self.data, self.bias\n",
        "                self.data,self.bias = tmp,tmpbis\n",
        "                self.floatmode = False\n",
        "\n",
        "    def forward(self,x):\n",
        "        assert not (self.floatmode and x.dtype == torch.int8)\n",
        "        assert not (not self.floatmode and x.dtype != torch.int8)\n",
        "        assert x.shape[1]== self.size\n",
        "\n",
        "        x = x.view(x.shape[0],self.size//8,1,8)\n",
        "        x = (x*self.data).sum(-1,dtype=x.dtype)\n",
        "        x = activation(x.view(x.shape[0],self.size)+self.bias)\n",
        "        return x\n",
        "\n",
        "with torch.no_grad():\n",
        "    layer = MyLinear(32)\n",
        "    x = torch.rand(128,32).cuda()*10-5\n",
        "    t0=time.time()\n",
        "    y = layer(x)\n",
        "    t1=time.time()-t0\n",
        "    layer.goINT()\n",
        "    t0=time.time()\n",
        "    z = layer(x.to(dtype=torch.int8)).float()\n",
        "    t2 = time.time()-t0\n",
        "\n",
        "print((y-z).abs().sum(),t1,t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6r6JPoKLaf",
        "outputId": "56965e02-413e-45ee-b0ed-1865bdfc2cc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2195.5115, device='cuda:0') 0.025692224502563477 0.013092994689941406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bon comme on a la flemme de faire une myconvolution, ben on va faire du transformer...\n",
        "(de toute façon, la différence de durée d'inférence ne motive pas à se casser les pieds !)\n",
        "\n",
        "### baseline\n",
        "construisons maintenant un petit réseau qui pourrait absorber des poids (en partie) int8"
      ],
      "metadata": {
        "id": "cNdXBNjo5UVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def channelPool(x):\n",
        "    return torch.max(x[:,::2],x[:,1::2])\n",
        "\n",
        "class SwinLike(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SwinLike, self).__init__()\n",
        "        self.proj = torch.nn.Conv2d(3,64,kernel_size=5,stride=3).cuda()\n",
        "\n",
        "        self.m1 = MyLinear(64*10*10)\n",
        "        self.m2 = MyLinear(32*10*10)\n",
        "        self.m3 = MyLinear(16*10*10)\n",
        "        self.m4 = MyLinear(8*10*10)\n",
        "        self.m5 = MyLinear(8*10*10)\n",
        "\n",
        "        self.final = torch.nn.Linear(800,10).cuda()\n",
        "        self.floatmode = True\n",
        "\n",
        "    def normalize(self):\n",
        "        self.m1.clamp()\n",
        "        self.m2.clamp()\n",
        "        self.m3.clamp()\n",
        "        self.m4.clamp()\n",
        "        self.m5.clamp()\n",
        "\n",
        "    def goINT(self):\n",
        "        if self.floatmode:\n",
        "            self.m1.goINT()\n",
        "            self.m2.goINT()\n",
        "            self.m3.goINT()\n",
        "            self.m4.goINT()\n",
        "            self.m5.goINT()\n",
        "            self.floatmode = False\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = activation(self.proj(x))\n",
        "        if not self.floatmode:\n",
        "            x = x.to(dtype=torch.int8)\n",
        "\n",
        "        x = channelPool(self.m1(x.flatten(1)))\n",
        "        x = channelPool(self.m2(x))\n",
        "        x = channelPool(self.m3(x))\n",
        "        x = self.m4(x)\n",
        "        x = self.m5(x)\n",
        "\n",
        "        return self.final(x.float())"
      ],
      "metadata": {
        "id": "udzmIEhtVmJE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "ogUioOi17-2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3676935-d1d2-4d0f-fbfa-dfebf38a12d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SwinLike()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "meanloss = []\n",
        "nb,nbOK = 0,0\n",
        "for i in range(60):\n",
        "    print(\"######\",i,\"######\")\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        loss = criterion(z,y.cuda().long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        net.normalize()\n",
        "\n",
        "        floss = float(loss)\n",
        "        meanloss.append(floss)\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "        if len(meanloss)==100:\n",
        "            print(sum(meanloss)/100, nbOK/nb)\n",
        "            meanloss=[]\n",
        "            # print([param for param in net.parameters()])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in trainloader:\n",
        "            z = net(x.cuda())\n",
        "            _,z = z.max(1)\n",
        "            good = (y.cuda()==z).float()\n",
        "            nb+=good.shape[0]\n",
        "            nbOK+=good.sum().cpu().numpy()\n",
        "        print(\"eval :\",nbOK/nb)"
      ],
      "metadata": {
        "id": "uYSGXvGy9h_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e144d4ca-4777-4870-dc07-3cb7a0e85a53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###### 0 ######\n",
            "2.3081105279922487 0.09453125\n",
            "2.307591047286987 0.095390625\n",
            "2.3060428500175476 0.09908854166666667\n",
            "eval : 0.09957\n",
            "###### 1 ######\n",
            "2.3076293110847472 0.0995432616260677\n",
            "2.295934431552887 0.10269236169615277\n",
            "2.2595479559898375 0.10799040646301439\n",
            "2.182074670791626 0.11569880761293282\n",
            "eval : 0.14946\n",
            "###### 2 ######\n",
            "2.113828160762787 0.150402364757988\n",
            "2.0561926758289335 0.15622675542993156\n",
            "2.0177841234207152 0.16281416736871665\n",
            "1.9733559489250183 0.1693573850039883\n",
            "eval : 0.19551333333333334\n",
            "###### 3 ######\n",
            "1.9472794234752655 0.19678964989982073\n",
            "1.9261636424064636 0.2015866892643934\n",
            "1.9133905482292175 0.20591935719148108\n",
            "1.8913186490535736 0.21034295141814097\n",
            "eval : 0.2284325\n",
            "###### 4 ######\n",
            "1.8658569514751435 0.2296469669408415\n",
            "1.8625450932979584 0.2331915056731064\n",
            "1.846966073513031 0.23646003793513834\n",
            "1.8310892140865327 0.23969318838485987\n",
            "eval : 0.252622\n",
            "###### 5 ######\n",
            "1.8143472981452942 0.25381010756089845\n",
            "1.7987209010124205 0.2565045510644863\n",
            "1.7949659717082977 0.25920844625112915\n",
            "1.768663614988327 0.26178697441928844\n",
            "eval : 0.27265833333333334\n",
            "###### 6 ######\n",
            "1.732638932466507 0.2739375724981546\n",
            "1.7534575974941253 0.27605887896313125\n",
            "1.7252475786209107 0.27826507639380754\n",
            "1.712102588415146 0.28049532629177826\n",
            "eval : 0.28956\n",
            "###### 7 ######\n",
            "1.6941245365142823 0.29074914132055857\n",
            "1.6991854691505432 0.29261136636036755\n",
            "1.6599417328834534 0.294648503947311\n",
            "1.6761331760883331 0.29648851116731684\n",
            "eval : 0.30405\n",
            "###### 8 ######\n",
            "1.6582256984710693 0.30528313824739006\n",
            "1.6687605714797973 0.3068176288539396\n",
            "1.644894483089447 0.30840089313094143\n",
            "1.644538391828537 0.3100743733011175\n",
            "eval : 0.31599333333333335\n",
            "###### 9 ######\n",
            "1.6433863067626953 0.3172123800485079\n",
            "1.6314165449142457 0.31860506430032237\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-215fd48888c4>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"######\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"######\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)"
      ],
      "metadata": {
        "id": "KDSGq6aCxxQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1216e2e-720a-423c-cb3e-55d25d71eec6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval : 0.3250900011377119 8.143792867660522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "net.goINT()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)"
      ],
      "metadata": {
        "id": "gmWUYiCDyUGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ben c'est vraiment pas terrible :-( et c'est pas plus rapide ?????"
      ],
      "metadata": {
        "id": "QbDK6uagGyU_"
      }
    }
  ]
}