{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4YdIkvi+Kt1oS7hIUor5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/AdversarialModel/blob/master/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##quantification\n",
        "L'objectif de ce notebook est d'apprendre un réseau qui pourra être utilisé en uint8.\n",
        "\n",
        "### speed up\n",
        "Regardons d'abord quelle est l'accélération qu'on peut espérer."
      ],
      "metadata": {
        "id": "hfkvfsm8D6yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    T = torch.zeros(100,5)\n",
        "    for i in range(100):\n",
        "        A = torch.randint(0, 256, (2000,1, 128), dtype=torch.uint8).cuda()\n",
        "        B = torch.randint(0, 256, (1,1000, 128), dtype=torch.uint8).cuda()\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = torch.matmul(A[:,0,:].float(),B[0].float().t()).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][0] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = torch._int_mm(A[:,0,:].to(dtype=torch.int8),B[0].t().to(dtype=torch.int8)).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][1] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A.float()*B.float()).sum(-1).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][2] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A.half()*B.half()).sum(-1,dtype=torch.half).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][3] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A*B).sum(-1,dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][4] = tf-t0\n",
        "\n",
        "\n",
        "print(T.mean(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phRiggfFsu1",
        "outputId": "7773e1e8-7743-4bf1-c762-f670896c27ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4892e-04, 8.6820e-05, 7.7779e-05, 6.6257e-05, 2.7828e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "on observe que le gain à espérer n'est pas du tout impressionnant - pire, la variance est très forte (ça semble dépendre du contenu de la matrice).\n",
        "néanmoins, cela testons quand même.\n",
        "\n",
        "### architecture\n",
        "\n",
        "Le point central du réseau sera que\n",
        "- si x est de dimension 8 avec ||x||_oo <= 5\n",
        "- si ||w||_oo<=3\n",
        "- alors |wx| <= 3 x 5 x 8 = 120\n",
        "-"
      ],
      "metadata": {
        "id": "TFrYkajBGYS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "donc si les poids sont des entiers dans [0,255], alors l'operation de produit suivi de cycle donnera le même résultat en float ou en uint8.\n",
        "\n",
        "on peut donc construire le module \"MyLinear\""
      ],
      "metadata": {
        "id": "V7ru9xxeJwTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(x):\n",
        "    if x.dtype==torch.int8:\n",
        "        return max(min(x,81),-17)//16\n",
        "    else:\n",
        "        return max(min(x,81),-17)/16\n",
        "\n",
        "class MyLinear(torch.nn.Module):\n",
        "    def __init__(self,inS,outS):\n",
        "        super(MyLinear, self).__init__()\n",
        "        assert inS%8==0 and outS%8==0\n",
        "        self.inS,self.outS=inS, outS\n",
        "        self.I = inS//8\n",
        "        self.J = outS//8\n",
        "        self.data = torch.rand(self.I,1,self.J,8).cuda() *\n",
        "        self.bias = torch.randint(0,256,(1,outS)).cuda().float()\n",
        "        self.data = torch.nn.Parameter(self.data)\n",
        "        self.bias = torch.nn.Parameter(self.bias)\n",
        "        #self.data.requires_grad_(True)\n",
        "        #self.bias.requires_grad_(True)\n",
        "        self.floatmode = True\n",
        "\n",
        "    def goINT(self):\n",
        "        if self.floatmode:\n",
        "            with torch.no_grad():\n",
        "                tmp = torch.round(self.data.clone()).to(dtype=torch.uint8)\n",
        "                tmpbis = torch.round(self.bias.clone()).to(dtype=torch.uint8)\n",
        "                del self.data, self.bias\n",
        "                self.data,self.bias = tmp,tmpbis\n",
        "                self.floatmode = False\n",
        "\n",
        "    def mm(self,i,x):\n",
        "        return ((self.data[i]*x.unsqueeze(1)).sum(-1)).to(dtype=x.dtype)\n",
        "\n",
        "    def forward(self,x):\n",
        "        assert not (self.floatmode and x.dtype == torch.uint8)\n",
        "        assert not (not self.floatmode and x.dtype != torch.uint8)\n",
        "        assert x.shape[1]== self.inS\n",
        "\n",
        "        out = torch.zeros(x.shape[0],self.outS).cuda().to(dtype=x.dtype)\n",
        "        for i in range(self.innerS):\n",
        "            out[:,i*self.J:(i+1)*self.J] = self.mm(i,x[:,i*self.I:(i+1)*self.I])\n",
        "        return cycle(out+self.bias)\n",
        "\n",
        "    \"\"\"\n",
        "    def step(self):\n",
        "        assert self.floatmode\n",
        "        with torch.no_grad():\n",
        "            self.data = (self.data - self.data.grad.sign())%256\n",
        "            self.bias = (self.bias - self.bias.grad.sign())%256\n",
        "        self.data.grad=None\n",
        "        self.bias.grad=None\n",
        "        self.data.requires_grad_(True)\n",
        "        self.bias.requires_grad_(True)\n",
        "    \"\"\"\n",
        "\n",
        "layer = MyLinear(32,64)\n",
        "x = torch.randint(0,256,(128,32)).float().cuda()\n",
        "t0=time.time()\n",
        "y = layer(x)\n",
        "t1=time.time()-t0\n",
        "layer.goINT()\n",
        "t0=time.time()\n",
        "z = layer(x.to(dtype=torch.uint8)).float()\n",
        "t2 = time.time()-t0\n",
        "\n",
        "print((y-z).abs().sum(),t1,t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6r6JPoKLaf",
        "outputId": "babb072f-c8af-4728-e01e-0f1e086ea7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0., device='cuda:0', grad_fn=<SumBackward0>) 0.001730203628540039 0.0014481544494628906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bon comme on a la flemme de faire une myconvolution, ben on va faire du transformer...\n",
        "(de toute façon, la durée d'inférence est quasiment identique !)\n",
        "\n",
        "### baseline\n",
        "construisons maintenant un petit réseau qui pourrait absorber des poids (en partie) uint8"
      ],
      "metadata": {
        "id": "cNdXBNjo5UVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def channelPool(x):\n",
        "    return torch.max(x[:,::2],x[:,1::2])\n",
        "\n",
        "class SwinLike(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SwinLike, self).__init__()\n",
        "        self.m1 = MyLinear(48,64)\n",
        "        self.m2 = MyLinear(80,128)\n",
        "\n",
        "        self.m3 = MyLinear(4096,4096,innerS=64)\n",
        "        self.m4 = MyLinear(2048,2048,innerS=32)\n",
        "        self.m5 = MyLinear(1024,1024,innerS=16)\n",
        "\n",
        "        self.final = torch.nn.Linear(1024,10).cuda()\n",
        "        self.floatmode = True\n",
        "\n",
        "    def goINT(self):\n",
        "        if self.floatmode:\n",
        "            self.m1.goINT()\n",
        "            self.m2.goINT()\n",
        "            self.m3.goINT()\n",
        "            self.m4.goINT()\n",
        "            self.m5.goINT()\n",
        "            self.floatmode = False\n",
        "\n",
        "    \"\"\"\n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            self.m1.step()\n",
        "            self.m2.step()\n",
        "            self.m3.step()\n",
        "            self.m4.step()\n",
        "            self.m5.step()\n",
        "            self.final.weight = torch.nn.Parameter(self.final.weight-0.001*self.final.weight.grad)\n",
        "            self.final.bias = torch.nn.Parameter(self.final.bias-0.001*self.final.bias.grad)\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self,x_):\n",
        "        assert not (self.floatmode and x_.dtype == torch.uint8)\n",
        "        assert not (not self.floatmode and x_.dtype != torch.uint8)\n",
        "\n",
        "        x = torch.zeros(x_.shape[0],64,8,8).cuda().to(dtype=x_.dtype)\n",
        "        for i in range(8):\n",
        "            for j in range(8):\n",
        "                tmp = x_[:,:,i*4:i*4+4,j*4:j*4+4].flatten(1)\n",
        "                tmpbis = channelPool(self.m1(tmp))\n",
        "                tmp = torch.cat([tmp,tmpbis],dim=1)\n",
        "                x[:,:,i,j] = channelPool(self.m2(tmp))\n",
        "\n",
        "        x = channelPool(self.m3(x.flatten(1)))\n",
        "        x = channelPool(self.m4(x))\n",
        "\n",
        "        x = self.m5(x).float()\n",
        "        return self.final(x/256)"
      ],
      "metadata": {
        "id": "udzmIEhtVmJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "ogUioOi17-2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc52a737-fabc-4d21-e36e-29ea6104e145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SwinLike()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n",
        "meanloss = []\n",
        "nb,nbOK = 0,0\n",
        "for i in range(60):\n",
        "    print(\"######\",i,\"######\")\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        loss = criterion(z,y.cuda().long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        floss = float(loss)\n",
        "        meanloss.append(floss)\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "        if len(meanloss)==100:\n",
        "            print(sum(meanloss)/100, nbOK/nb)\n",
        "            # print(net.m3.data.dtype,net.m3.data.abs().sum())\n",
        "            meanloss=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in trainloader:\n",
        "            z = net(x.cuda())\n",
        "            _,z = z.max(1)\n",
        "            good = (y.cuda()==z).float()\n",
        "            nb+=good.shape[0]\n",
        "            nbOK+=good.sum().cpu().numpy()\n",
        "        print(\"eval :\",nbOK/nb)\n",
        "\n",
        "        #print([param for param in net.parameters()])"
      ],
      "metadata": {
        "id": "uYSGXvGy9h_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d125db25-1dc3-469a-a7cd-858e7f9e1d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###### 0 ######\n",
            "2.3129075598716735 0.102890625\n",
            "torch.float32 tensor(33357384., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.315036644935608 0.1005859375\n",
            "torch.float32 tensor(33359692., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.312225079536438 0.09997395833333333\n",
            "torch.float32 tensor(33358964., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10043\n",
            "###### 1 ######\n",
            "2.3100241899490355 0.10037369503321733\n",
            "torch.float32 tensor(33360920., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.309630353450775 0.10034926986801461\n",
            "torch.float32 tensor(33359568., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3095856142044067 0.1006374652865438\n",
            "torch.float32 tensor(33359048., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.307660541534424 0.10085846136207292\n",
            "torch.float32 tensor(33360716., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.100155\n",
            "###### 2 ######\n",
            "2.310331916809082 0.10006722556153116\n",
            "torch.float32 tensor(33360376., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3098173570632934 0.10006787414459982\n",
            "torch.float32 tensor(33360584., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3078731203079226 0.10037559674248807\n",
            "torch.float32 tensor(33361420., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3057742619514467 0.10068382743951076\n",
            "torch.float32 tensor(33364360., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10048666666666667\n",
            "###### 3 ######\n",
            "2.3056797552108765 0.10050550985974903\n",
            "torch.float32 tensor(33364816., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3074466967582703 0.10047556409996965\n",
            "torch.float32 tensor(33366160., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3058150124549868 0.10053303996888067\n",
            "torch.float32 tensor(33364300., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3065931391716004 0.10052770757277918\n",
            "torch.float32 tensor(33365212., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.1003225\n",
            "###### 4 ######\n",
            "2.306115369796753 0.10036628044922492\n",
            "torch.float32 tensor(33367016., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3067952489852903 0.10040056731064091\n",
            "torch.float32 tensor(33365260., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.305685608386993 0.10042119160963998\n",
            "torch.float32 tensor(33363796., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3059904408454894 0.10046771164403352\n",
            "torch.float32 tensor(33364214., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.100208\n",
            "###### 5 ######\n",
            "2.3078060722351075 0.10015817779183803\n",
            "torch.float32 tensor(33365116., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3063008069992064 0.1002159827213823\n",
            "torch.float32 tensor(33363794., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3060799765586855 0.10017125865703101\n",
            "torch.float32 tensor(33366456., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3056049966812133 0.10022419876506909\n",
            "torch.float32 tensor(33367552., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10008166666666667\n",
            "###### 6 ######\n",
            "2.306083583831787 0.10005898713487293\n",
            "torch.float32 tensor(33365840., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3055973172187807 0.10014329236806775\n",
            "torch.float32 tensor(33366152., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3058383440971375 0.10011351563290499\n",
            "torch.float32 tensor(33366922., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.305539696216583 0.10018564663294655\n",
            "torch.float32 tensor(33370314., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10019571428571429\n",
            "###### 7 ######\n",
            "2.3061736583709718 0.10018585890540968\n",
            "torch.float32 tensor(33369814., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.306013236045837 0.10015203977449283\n",
            "torch.float32 tensor(33367432., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3050508213043215 0.10015620229423823\n",
            "torch.float32 tensor(33368092., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3049971628189088 0.10019103399494149\n",
            "torch.float32 tensor(33365840., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10008125\n",
            "###### 8 ######\n",
            "2.304572901725769 0.10009441236950332\n",
            "torch.float32 tensor(33365418., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3059240794181823 0.10006009615384616\n",
            "torch.float32 tensor(33365586., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.303556001186371 0.100126255366452\n",
            "torch.float32 tensor(33366160., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3051449847221375 0.10012788810027182\n",
            "torch.float32 tensor(33365102., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10005777777777777\n",
            "###### 9 ######\n",
            "2.305333216190338 0.10006393019086787\n",
            "torch.float32 tensor(33367908., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3069844460487365 0.09999913341883601\n",
            "torch.float32 tensor(33368128., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3051911044120788 0.10002265034702042\n",
            "torch.float32 tensor(33368804., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3055741238594054 0.10002550676245404\n",
            "torch.float32 tensor(33366584., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.100005\n",
            "###### 10 ######\n",
            "2.305305287837982 0.10004943055994939\n",
            "torch.float32 tensor(33366408., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.306100535392761 0.09998535613870665\n",
            "torch.float32 tensor(33367776., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3061807703971864 0.09992864856525764\n",
            "torch.float32 tensor(33367028., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.304833698272705 0.09997999847607436\n",
            "torch.float32 tensor(33366598., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.09997545454545455\n",
            "###### 11 ######\n",
            "2.30541410446167 0.0999791492910759\n",
            "torch.float32 tensor(33366624., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.305445828437805 0.10001848113502601\n",
            "torch.float32 tensor(33364824., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3069341707229616 0.09997434708048691\n",
            "torch.float32 tensor(33366378., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.09998083333333334\n",
            "###### 12 ######\n",
            "2.3058712601661684 0.0999830144942982\n",
            "torch.float32 tensor(33366682., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.304261426925659 0.09999802277760203\n",
            "torch.float32 tensor(33370228., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.306355493068695 0.09998418423249504\n",
            "torch.float32 tensor(33370792., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.305722382068634 0.09999322265826707\n",
            "torch.float32 tensor(33368838., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10004769230769231\n",
            "###### 13 ######\n",
            "2.305886170864105 0.10003793650013516\n",
            "torch.float32 tensor(33368096., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.30532133102417 0.10001551359112258\n",
            "torch.float32 tensor(33367926., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.30411013841629 0.1000213891499771\n",
            "torch.float32 tensor(33367960., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.30641215801239 0.10002640655956842\n",
            "torch.float32 tensor(33367688., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10008285714285714\n",
            "###### 14 ######\n",
            "2.305091288089752 0.10006926392119304\n",
            "torch.float32 tensor(33367052., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3062678956985474 0.10003827337641795\n",
            "torch.float32 tensor(33366432., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.30530091047287 0.10005682581627626\n",
            "torch.float32 tensor(33365264., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.305248448848724 0.10009169552093043\n",
            "torch.float32 tensor(33364988., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "eval : 0.10011066666666667\n",
            "###### 15 ######\n",
            "2.305996994972229 0.10012097203020312\n",
            "torch.float32 tensor(33364494., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3058413910865783 0.1001127016766846\n",
            "torch.float32 tensor(33362556., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.3049852418899537 0.10009868765031894\n",
            "torch.float32 tensor(33362660., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "2.304888513088226 0.1001315721248574\n",
            "torch.float32 tensor(33360176., device='cuda:0', grad_fn=<SumBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ac5fe24df04a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)"
      ],
      "metadata": {
        "id": "KDSGq6aCxxQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "net.goINT()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        z = net(torch.round((x.cuda()*256)).to(dtype=torch.uint8))\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)"
      ],
      "metadata": {
        "id": "gmWUYiCDyUGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ben c'est vraiment pas terrible :-( et c'est pas plus rapide ?????"
      ],
      "metadata": {
        "id": "QbDK6uagGyU_"
      }
    }
  ]
}