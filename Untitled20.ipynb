{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNM0ner+hnQdIpSI9C7k2kd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/AdversarialModel/blob/master/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##quantification\n",
        "L'objectif de ce notebook est d'apprendre un réseau qui pourra être utilisé en uint8.\n",
        "\n",
        "### speed up\n",
        "Regardons d'abord quelle est l'accélération qu'on peut espérer."
      ],
      "metadata": {
        "id": "hfkvfsm8D6yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lPxYWtRTXYYC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    T = torch.zeros(100,5)\n",
        "    for i in range(100):\n",
        "        A = torch.randint(0, 256, (2000,1, 128), dtype=torch.uint8).cuda()\n",
        "        B = torch.randint(0, 256, (1,1000, 128), dtype=torch.uint8).cuda()\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = torch.matmul(A[:,0,:].float(),B[0].float().t()).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][0] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = torch._int_mm(A[:,0,:].to(dtype=torch.int8),B[0].t().to(dtype=torch.int8)).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][1] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A.float()*B.float()).sum(-1).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][2] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A.half()*B.half()).sum(-1,dtype=torch.half).to(dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][3] = tf-t0\n",
        "\n",
        "        t0 = time.time()\n",
        "        C = (A*B).sum(-1,dtype=torch.uint8)\n",
        "        tf = time.time()\n",
        "        T[i][4] = tf-t0\n",
        "\n",
        "\n",
        "print(T.mean(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phRiggfFsu1",
        "outputId": "7773e1e8-7743-4bf1-c762-f670896c27ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4892e-04, 8.6820e-05, 7.7779e-05, 6.6257e-05, 2.7828e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "on observe que le gain à espérer n'est pas du tout impressionnant - pire, la variance est très forte (ça semble dépendre du contenu de la matrice).\n",
        "néanmoins, cela testons quand même.\n",
        "\n",
        "### architecture\n",
        "\n",
        "Le point central du réseau sera que\n",
        "- si x est de dimension 8 avec ||x||_oo <= 5\n",
        "- si ||w||_oo<=3\n",
        "- alors |wx| <= 3 x 5 x 8 = 120\n",
        "- donc activation(x)//16 est toujours un vecteur de dimension 8 avec ||x||_oo <= 5"
      ],
      "metadata": {
        "id": "TFrYkajBGYS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "on peut donc construire le module \"MyLinear\""
      ],
      "metadata": {
        "id": "V7ru9xxeJwTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(x):\n",
        "    if x.dtype==torch.int8:\n",
        "        return torch.clamp(x,-17,81)//16\n",
        "    else:\n",
        "        return torch.clamp(x,-17,81)/16\n",
        "\n",
        "class MyLinear(torch.nn.Module):\n",
        "    def __init__(self,size):\n",
        "        super(MyLinear, self).__init__()\n",
        "        assert size%8==0\n",
        "        self.size=size\n",
        "        self.data = torch.rand(1,size//8,8,8).cuda() * 6 - 3\n",
        "        self.bias = torch.rand(1,size).cuda() * 6 - 3\n",
        "        self.data = torch.nn.Parameter(self.data)\n",
        "        self.bias = torch.nn.Parameter(self.bias)\n",
        "        self.floatmode = True\n",
        "\n",
        "    def clamp(self):\n",
        "        with torch.no_grad():\n",
        "            torch.clamp(self.data,-3,3)\n",
        "            torch.clamp(self.bias,-3,3)\n",
        "\n",
        "    def goINT(self):\n",
        "        if self.floatmode:\n",
        "            with torch.no_grad():\n",
        "                tmp = torch.round(self.data.clone()).to(dtype=torch.uint8)\n",
        "                tmpbis = torch.round(self.bias.clone()).to(dtype=torch.uint8)\n",
        "                del self.data, self.bias\n",
        "                self.data,self.bias = tmp,tmpbis\n",
        "                self.floatmode = False\n",
        "\n",
        "    def forward(self,x):\n",
        "        assert not (self.floatmode and x.dtype == torch.uint8)\n",
        "        assert not (not self.floatmode and x.dtype != torch.uint8)\n",
        "        assert x.shape[1]== self.size\n",
        "\n",
        "        x = x.view(x.shape[0],self.size//8,1,8)\n",
        "        x = (x*self.data).sum(-1,dtype=x.dtype)\n",
        "        x = activation(x.view(x.shape[0],self.size)+self.bias)\n",
        "        return x\n",
        "\n",
        "with torch.no_grad():\n",
        "    layer = MyLinear(32)\n",
        "    x = torch.rand(128,32).cuda()*10-5\n",
        "    t0=time.time()\n",
        "    y = layer(x)\n",
        "    t1=time.time()-t0\n",
        "    layer.goINT()\n",
        "    t0=time.time()\n",
        "    z = layer(x.to(dtype=torch.uint8)).float()\n",
        "    t2 = time.time()-t0\n",
        "\n",
        "print((y-z).abs().sum(),t1,t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb6r6JPoKLaf",
        "outputId": "cfce5dbc-246f-4571-be9d-4e050e11c6b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(20465.1602, device='cuda:0') 0.000194549560546875 0.0005249977111816406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bon comme on a la flemme de faire une myconvolution, ben on va faire du transformer...\n",
        "(de toute façon, la différence de durée d'inférence ne motive pas à se casser les pieds !)\n",
        "\n",
        "### baseline\n",
        "construisons maintenant un petit réseau qui pourrait absorber des poids (en partie) uint8"
      ],
      "metadata": {
        "id": "cNdXBNjo5UVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def channelPool(x):\n",
        "    return torch.max(x[:,::2],x[:,1::2])\n",
        "\n",
        "class SwinLike(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SwinLike, self).__init__()\n",
        "        self.proj = torch.nn.Conv2d(3,64,kernel_size=5,stride=3).cuda()\n",
        "\n",
        "        self.m1 = MyLinear(64*10*10)\n",
        "        self.m2 = MyLinear(32*10*10)\n",
        "        self.m3 = MyLinear(16*10*10)\n",
        "        self.m4 = MyLinear(8*10*10)\n",
        "        self.m5 = MyLinear(4*10*10)\n",
        "\n",
        "        self.final = torch.nn.Linear(400,10).cuda()\n",
        "        self.floatmode = True\n",
        "\n",
        "    def goINT(self):\n",
        "        if self.floatmode:\n",
        "            self.m1.goINT()\n",
        "            self.m2.goINT()\n",
        "            self.m3.goINT()\n",
        "            self.m4.goINT()\n",
        "            self.m5.goINT()\n",
        "            self.floatmode = False\n",
        "\n",
        "    def forward(self,x_):\n",
        "        assert not (self.floatmode and x_.dtype == torch.uint8)\n",
        "        assert not (not self.floatmode and x_.dtype != torch.uint8)\n",
        "\n",
        "        x = activation(self.proj(x_.float())).to(dtype=x_.dtype)\n",
        "\n",
        "        x = channelPool(self.m1(x.flatten(1)))\n",
        "        x = channelPool(self.m2(x))\n",
        "        x = channelPool(self.m3(x))\n",
        "        x = channelPool(self.m4(x))\n",
        "        x = self.m5(x)\n",
        "\n",
        "        return self.final(x.float())"
      ],
      "metadata": {
        "id": "udzmIEhtVmJE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "ogUioOi17-2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d869e1-0001-4036-e229-8011711a7032"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to build/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28719783.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting build/cifar-10-python.tar.gz to build\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SwinLike()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n",
        "meanloss = []\n",
        "nb,nbOK = 0,0\n",
        "for i in range(60):\n",
        "    print(\"######\",i,\"######\")\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        loss = criterion(z,y.cuda().long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        floss = float(loss)\n",
        "        meanloss.append(floss)\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "        if len(meanloss)==100:\n",
        "            print(sum(meanloss)/100, nbOK/nb)\n",
        "            meanloss=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in trainloader:\n",
        "            z = net(x.cuda())\n",
        "            _,z = z.max(1)\n",
        "            good = (y.cuda()==z).float()\n",
        "            nb+=good.shape[0]\n",
        "            nbOK+=good.sum().cpu().numpy()\n",
        "        print(\"eval :\",nbOK/nb)"
      ],
      "metadata": {
        "id": "uYSGXvGy9h_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "086bd888-be51-4fcb-ea7a-0ed1fa7c696d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###### 0 ######\n",
            "2.3050578093528746 0.098203125\n",
            "2.3044378328323365 0.0991796875\n",
            "2.305200233459473 0.09841145833333333\n",
            "eval : 0.09869\n",
            "###### 1 ######\n",
            "2.3049194264411925 0.09856453653906991\n",
            "2.3042122673988343 0.0985941449031171\n",
            "2.305135109424591 0.09860199444584701\n",
            "2.304143874645233 0.0987230566383857\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ab00b4624562>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        z = net(x.cuda())\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)"
      ],
      "metadata": {
        "id": "KDSGq6aCxxQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "net.goINT()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        z = net(torch.round((x.cuda()*256)).to(dtype=torch.uint8))\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)"
      ],
      "metadata": {
        "id": "gmWUYiCDyUGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ben c'est vraiment pas terrible :-( et c'est pas plus rapide ?????"
      ],
      "metadata": {
        "id": "QbDK6uagGyU_"
      }
    }
  ]
}