{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDuneJtln64CVhiGCgAkBD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/AdversarialModel/blob/master/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##quantification\n",
        "L'objectif de ce notebook est d'essayer d'effectuer un apprentissage float32 propice à être caster en int8.\n",
        "Pour cela, une loss supplémentaire sur les poids (forcés à être près d'un entier) et l'utilisation d'une double activation relu + \"cyclique\".\n",
        "\n",
        "Ce test préliminaire est réalisé sur CIFAR10.\n",
        "\n",
        "### activation\n",
        "Il convient d'abord de selectionner une activation continue qui a le même comportement en float et en uint8"
      ],
      "metadata": {
        "id": "hfkvfsm8D6yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def cycle(x):\n",
        "    assert x.dtype in [torch.half, torch.float,torch.uint8]\n",
        "    if x.dtype != torch.uint8:\n",
        "        x = x % 256\n",
        "    return x - 2 * (x-128)*(x>128).to(dtype=x.dtype)\n",
        "\n",
        "x = (torch.arange(1000)-500)\n",
        "y = cycle(x.float())\n",
        "z = cycle(x.to(dtype=torch.uint8)).float()\n",
        "assert all(y==z)\n",
        "\n",
        "y = cycle(x)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x, y)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "xa3GYPIpnP2E",
        "outputId": "2a7beec4-a431-40c7-a0b0-f805293004db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0cd0d5c2571a>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-0cd0d5c2571a>\u001b[0m in \u001b[0;36mcycle\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### baseline\n",
        "construisons maintenant un petit réseau qui pourrait absorber des poids (en partie) uint8"
      ],
      "metadata": {
        "id": "cNdXBNjo5UVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def channelPool(x):\n",
        "    x1,x2 = x[:,::2,:,:],x[:,1::2,:,:]\n",
        "    return torch.max(x1,x2)\n",
        "\n",
        "def funconcat(x1,x2):\n",
        "    n,c,h,w = x1.shape\n",
        "    x = torch.zeros(n,2*c,h,w).to(dtype=x1.dtype)\n",
        "    x[:,::2,:,:],x[:,1::2,:,:] = x1,x2\n",
        "    return x\n",
        "\n",
        "class Funblock(torch.nn.Module):\n",
        "    def __init__(self,size):\n",
        "        super(Funblock, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(size, 2*size,kernel_size=3,padding=1,group=8)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1 = cycle(self.conv(x))\n",
        "        x1 = channelPool(x1)\n",
        "        return funconcat(x1,x)"
      ],
      "metadata": {
        "id": "udzmIEhtVmJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcrhY_AzD5Qh"
      },
      "outputs": [],
      "source": [
        "class Baseline(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Baseline, self).__init__()\n",
        "        # very few operation: can be done in float\n",
        "        self.proj1 = torch.nn.Conv2d(3, 16,kernel_size=3,padding=1)\n",
        "        self.proj2 = torch.nn.Conv2d(16, 64,kernel_size=2,stride=2)\n",
        "        self.proj3 = torch.nn.Conv2d(64, 32,kernel_size=1)\n",
        "\n",
        "        # could be uint8\n",
        "        self.c1 = Funblock(32)\n",
        "        self.c2 = Funblock(64)\n",
        "        self.c3 = Funblock(128)\n",
        "        self.c4 = Funblock(256)\n",
        "        self.c5 = Funblock(512)\n",
        "\n",
        "        # very few operation: can be done in float\n",
        "        self.f1 = torch.nn.Linear(512,1024)\n",
        "        self.f2 = torch.nn.Linear(1024,2048)\n",
        "        self.f3 = torch.nn.Linear(2048,2048)\n",
        "        self.f4 = torch.nn.Linear(4096,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        p = torch.nn.functional.leaky_relu(self.proj1(x.float()))\n",
        "        p = torch.nn.functional.leaky_relu(self.proj2(p))\n",
        "        p = cycle(self.proj3(p)).to(dtype=x.dtype)\n",
        "\n",
        "        x = cycle(self.c1(x))\n",
        "        x = cycle(self.c2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x,kernel_size=2,stride=2)\n",
        "        x = cycle(self.c3(x))\n",
        "        x = cycle(self.c4(x))\n",
        "        x = cycle(self.c5(x))\n",
        "        x = torch.nn.functional.max_pool2d(x,kernel_size=8,stride=8)\n",
        "\n",
        "        x = x[:,:,0,0].float()\n",
        "\n",
        "        x = torch.nn.functional.leaky_relu(self.f1(x))\n",
        "        x = torch.nn.functional.leaky_relu(self.f2(x))\n",
        "        x = torch.cat([x,torch.nn.functional.leaky_relu(self.f3(x))],dim=1)\n",
        "        return self.f4(x)\n",
        "\n",
        "net = Baseline()\n",
        "with torch.no_grad():\n",
        "    print(net(torch.rand(2,3,32,32)).shape)"
      ]
    }
  ]
}