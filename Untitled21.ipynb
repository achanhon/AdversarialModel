{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtok9v0uxYfSR8RlD0M3L3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achanhon/AdversarialModel/blob/master/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extraction de points d'intérêt\n",
        "\n",
        "Il existe déjà des modèles qui vont extraire de façon non supervisée des points d'intérêt dans des images comme DinoV2.\n",
        "\n",
        "On cherche ici à réaliser cette tache de façon explicite.\n",
        "\n",
        "-> on prend une image\n",
        "-> on crée une carte de features\n",
        "-> on voudrait que la classif se comporte \"aussi bien\" avec soit la carte de feature entière, soit k points seulement\n",
        "\n",
        "(ça peut être vit mais pas forcément)"
      ],
      "metadata": {
        "id": "qYmSevCp3VjW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oos5ycG23Ux7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KeypointSelector(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KeypointSelector, self).__init__()\n",
        "        self.encoder = torchvision.models.efficientnet_v2_s(weights=\"DEFAULT\").features\n",
        "        del self.encoder[3:]\n",
        "\n",
        "        self.projector = torch.nn.Conv2d(48,128,kernel_size=1)\n",
        "\n",
        "        self.rawclassif1 = torch.nn.Conv2d(128,4096,kernel_size=8)\n",
        "        self.rawclassif2 = torch.nn.Linear(4096,10)\n",
        "\n",
        "        self.selector1 = torch.nn.Conv2d(128,256,kernel_size=3,padding=1)\n",
        "        self.selector2 = torch.nn.Conv2d(256,1,kernel_size=1)\n",
        "\n",
        "        self.softclassif1 = torch.nn.Conv2d(128,4096,kernel_size=8)\n",
        "        self.softclassif2 = torch.nn.Linear(4096,10)\n",
        "\n",
        "        self.K = 4\n",
        "        self.fineclassif1 = torch.nn.Linear(512,4096)\n",
        "        self.fineclassif2 = torch.nn.Linear(4096,10)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        with torch.no_grad():\n",
        "            f = self.encoder((x-0.5)*2)\n",
        "            assert f.shape==(x.shape[0],48,8,8)\n",
        "        f = torch.nn.functional.leaky_relu(self.projector(f))\n",
        "\n",
        "        praw = torch.nn.functional.leaky_relu(self.rawclassif1(f))\n",
        "        praw = self.rawclassif2(praw.flatten(1))\n",
        "\n",
        "        heatmap = torch.nn.functional.leaky_relu(self.selector1(f))\n",
        "        heatmap = torch.nn.functional.leaky_relu(self.selector2(heatmap))\n",
        "        assert heatmap.shape == (x.shape[0],1,8,8)\n",
        "\n",
        "        soft,_ = heatmap.flatten(1).max(1)\n",
        "        # assert soft.shape==x.shape[0],soft.shape => ça marche mais il aime pas\n",
        "        soft = heatmap/(soft.view(x.shape[0],1,1,1)+1)\n",
        "\n",
        "        psoft = torch.nn.functional.leaky_relu(self.softclassif1(f*soft))\n",
        "        psoft = self.softclassif2(psoft.flatten(1))\n",
        "\n",
        "        val,I = torch.topk( heatmap.flatten(1), self.K, dim=1)\n",
        "\n",
        "        subf = torch.zeros(x.shape[0],128,self.K).cuda()\n",
        "        f =f.flatten(2)\n",
        "        for i in range(self.K):\n",
        "            subf[:,:,i] = f[:,:,I[:,i]]\n",
        "\n",
        "        subf = subf.flatten(1)\n",
        "        pfine = torch.nn.functional.leaky_relu(self.rawclassif1(subf))\n",
        "        pfine = self.rawclassif2(pfine)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val = val[:,-1].view(x.shape[0],1,1,1)\n",
        "            heatmap = torch.nn.functional.interpolate(heatmap,(x.shape[2],x.shape[3]),mode=\"bilinear\")\n",
        "            maskedinput = x.clone() * (heatmap>val)\n",
        "\n",
        "        return praw,psoft, pfine,maskedinput"
      ],
      "metadata": {
        "id": "nzBEteUL4o6M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root=\"build\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "ogUioOi17-2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c9c47a-5416-422e-f555-12dc712d05f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = KeypointSelector()\n",
        "net = net.cuda()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "meanloss = []\n",
        "nb,nbOK = 0,0\n",
        "for i in range(60):\n",
        "    print(\"######\",i,\"######\")\n",
        "    for x,y in trainloader:\n",
        "        praw,psoft,pfine,_ = net(x.cuda())\n",
        "        loss = criterion(praw,y.cuda().long())*0.25+criterion(psoft,y.cuda().long())*0.25+criterion(pfine,y.cuda().long())*0.5\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        net.normalize()\n",
        "\n",
        "        floss = float(loss)\n",
        "        meanloss.append(floss)\n",
        "        _,z = pfine.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "        if len(meanloss)==100:\n",
        "            print(sum(meanloss)/100, nbOK/nb)\n",
        "            meanloss=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in trainloader:\n",
        "            _,_,z,_ = net(x.cuda())\n",
        "            _,z = z.max(1)\n",
        "            good = (y.cuda()==z).float()\n",
        "            nb+=good.shape[0]\n",
        "            nbOK+=good.sum().cpu().numpy()\n",
        "        print(\"eval :\",nbOK/nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "XsSmPjPy6kDA",
        "outputId": "229c8642-aa1f-4d29-a568-f56b5dcf015e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###### 0 ######\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d3750e73cecc>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"######\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"######\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpraw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsoft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpfine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpraw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsoft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-32dd6c1875b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0msubf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0msubf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.FloatTensor{[64, 128, 64]}, size=[64, 128]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for x,y in trainloader:\n",
        "        _,_,z,visu = net(x.cuda())\n",
        "        _,z = z.max(1)\n",
        "        good = (y.cuda()==z).float()\n",
        "        nb+=good.shape[0]\n",
        "        nbOK+=good.sum().cpu().numpy()\n",
        "    print(\"eval :\",nbOK/nb,time.time()-t0)\n",
        "\n",
        "    visu1 = torchvision.utils.make_grid(x[0:32], nrow=8)\n",
        "    visu2 = torchvision.utils.make_grid(visu[0:32], nrow=8)\n",
        "    visu = torch.cat([visu1,visu2],dim=-1)\n",
        "\n",
        "    visu = visu.cpu().numpy().transpose(1,2,0)\n",
        "    plt.imshow(visu)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kx5PaSzsDFXk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}